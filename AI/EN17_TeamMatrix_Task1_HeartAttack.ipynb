{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yP13oWROk3o8",
        "outputId": "4ac92104-ab3c-482f-b53e-d27d48c6035d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Everything works!\n",
            "Pandas: 2.2.2\n",
            "Scikit-learn: 1.6.1\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import sklearn\n",
        "print(\"✅ Everything works!\")\n",
        "print(f\"Pandas: {pd.__version__}\")\n",
        "print(f\"Scikit-learn: {sklearn.__version__}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "print(\"✅ All imports successful!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qb8ckXFik6Qr",
        "outputId": "50df60ee-1ad8-4b7f-b3c4-b2bab7cd156c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ All imports successful!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the datasets\n",
        "train_data = pd.read_csv('Heart_Attack_training_dataset.csv')\n",
        "test_data = pd.read_csv('Hear_Attack_evaluation_dataset')\n",
        "\n",
        "# Show first few rows\n",
        "print(\"Training data loaded!\")\n",
        "print(f\"Number of rows: {len(train_data)}\")\n",
        "print(f\"Number of columns: {len(train_data.columns)}\")\n",
        "print(\"\\nFirst 5 rows:\")\n",
        "print(train_data.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "id": "tZS6t8oQlsF2",
        "outputId": "3ef9abb5-cc40-43b3-cdbd-0dd5e0fed2f8"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'Hear_Attack_evaluation_dataset'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2595001267.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Load the datasets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtrain_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Heart_Attack_training_dataset.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtest_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Hear_Attack_evaluation_dataset'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Show first few rows\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Hear_Attack_evaluation_dataset'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the datasets\n",
        "train_data = pd.read_csv('heart_train.csv')\n",
        "test_data = pd.read_csv('heart_test.csv')\n",
        "\n",
        "# Show first few rows\n",
        "print(\"Training data loaded!\")\n",
        "print(f\"Number of rows: {len(train_data)}\")\n",
        "print(f\"Number of columns: {len(train_data.columns)}\")\n",
        "print(\"\\nFirst 5 rows:\")\n",
        "print(train_data.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "id": "fiHDbudxmAVO",
        "outputId": "e0519cad-dccb-4254-aba7-e3439dff47b1"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'heart_train.csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3061929437.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Load the datasets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'heart_train.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mtest_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'heart_test.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Show first few rows\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'heart_train.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the datasets\n",
        "train_data = pd.read_csv('heart_train.csv')\n",
        "test_data = pd.read_csv('heart_test.csv')\n",
        "\n",
        "# Show first few rows\n",
        "print(\"Training data loaded!\")\n",
        "print(f\"Number of rows: {len(train_data)}\")\n",
        "print(f\"Number of columns: {len(train_data.columns)}\")\n",
        "print(\"\\nFirst 5 rows:\")\n",
        "print(train_data.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mmwZremWmFPW",
        "outputId": "babedcbf-bf80-4e93-f945-9c1c935fcb7c"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training data loaded!\n",
            "Number of rows: 7963\n",
            "Number of columns: 26\n",
            "\n",
            "First 5 rows:\n",
            "  patient_id  age     sex  chol       bp  hr  diabetes  family_history  \\\n",
            "0    BMW7812   67    Male   208   158/88  72         0               0   \n",
            "1    CZE1114   21    Male   389   165/93  98         1               1   \n",
            "2    BNI9906   21  Female   324   174/99  72         1               0   \n",
            "3    JLN3497   84    Male   383  163/100  73         1               1   \n",
            "4    GFO8847   66    Male   318    91/88  93         1               1   \n",
            "\n",
            "   smoking  obesity  ...  sedentary_hr  income        bmi  triglycerides  \\\n",
            "0        1        0  ...      6.615001  261404  31.251233            286   \n",
            "1        1        1  ...      4.963459  285768  27.194973            235   \n",
            "2        0        0  ...      9.463426  235282  28.176571            587   \n",
            "3        1        0  ...      7.648981  125640  36.464704            378   \n",
            "4        1        1  ...      1.514821  160555  21.809144            231   \n",
            "\n",
            "   phys_act_days  sleep_hr    country      continent           hemisphere  \\\n",
            "0              0         6  Argentina  South America  Southern Hemisphere   \n",
            "1              1         7     Canada  North America  Northern Hemisphere   \n",
            "2              4         4     France         Europe  Northern Hemisphere   \n",
            "3              3         4     Canada  North America  Northern Hemisphere   \n",
            "4              1         5   Thailand           Asia  Northern Hemisphere   \n",
            "\n",
            "   heart_attack_risk  \n",
            "0                  0  \n",
            "1                  0  \n",
            "2                  0  \n",
            "3                  0  \n",
            "4                  0  \n",
            "\n",
            "[5 rows x 26 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check for missing values\n",
        "print(\"Missing values in each column:\")\n",
        "print(train_data.isnull().sum())\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"Target variable distribution:\")\n",
        "print(train_data['heart_attack_risk'].value_counts())\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"Basic statistics:\")\n",
        "print(train_data.describe())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qDU45CgumXJA",
        "outputId": "68e4a1d0-ca31-45e6-8345-38295757448f"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Missing values in each column:\n",
            "patient_id           0\n",
            "age                  0\n",
            "sex                  0\n",
            "chol                 0\n",
            "bp                   0\n",
            "hr                   0\n",
            "diabetes             0\n",
            "family_history       0\n",
            "smoking              0\n",
            "obesity              0\n",
            "alcohol              0\n",
            "exercise_hr_wk       0\n",
            "diet                 0\n",
            "prev_heart_prob      0\n",
            "med_use              0\n",
            "stress_lvl           0\n",
            "sedentary_hr         0\n",
            "income               0\n",
            "bmi                  0\n",
            "triglycerides        0\n",
            "phys_act_days        0\n",
            "sleep_hr             0\n",
            "country              0\n",
            "continent            0\n",
            "hemisphere           0\n",
            "heart_attack_risk    0\n",
            "dtype: int64\n",
            "\n",
            "==================================================\n",
            "Target variable distribution:\n",
            "heart_attack_risk\n",
            "0    5224\n",
            "1    2739\n",
            "Name: count, dtype: int64\n",
            "\n",
            "==================================================\n",
            "Basic statistics:\n",
            "               age         chol           hr     diabetes  family_history  \\\n",
            "count  7963.000000  7963.000000  7963.000000  7963.000000     7963.000000   \n",
            "mean     53.685922   259.574658    75.102474     0.653020        0.489640   \n",
            "std      21.237794    80.824235    20.583831     0.476039        0.499924   \n",
            "min      18.000000   120.000000    40.000000     0.000000        0.000000   \n",
            "25%      35.000000   191.000000    57.000000     0.000000        0.000000   \n",
            "50%      54.000000   259.000000    75.000000     1.000000        0.000000   \n",
            "75%      72.000000   329.000000    93.000000     1.000000        1.000000   \n",
            "max      90.000000   400.000000   110.000000     1.000000        1.000000   \n",
            "\n",
            "           smoking      obesity      alcohol  exercise_hr_wk  prev_heart_prob  \\\n",
            "count  7963.000000  7963.000000  7963.000000     7963.000000      7963.000000   \n",
            "mean      0.896521     0.504207     0.597890        9.999996         0.495165   \n",
            "std       0.304602     0.500014     0.490355        5.778830         0.500008   \n",
            "min       0.000000     0.000000     0.000000        0.002442         0.000000   \n",
            "25%       1.000000     0.000000     0.000000        4.979003         0.000000   \n",
            "50%       1.000000     1.000000     1.000000       10.062622         0.000000   \n",
            "75%       1.000000     1.000000     1.000000       15.038864         1.000000   \n",
            "max       1.000000     1.000000     1.000000       19.998709         1.000000   \n",
            "\n",
            "           med_use   stress_lvl  sedentary_hr         income          bmi  \\\n",
            "count  7963.000000  7963.000000   7963.000000    7963.000000  7963.000000   \n",
            "mean      0.498179     5.472812      5.976430  158283.114279    28.891190   \n",
            "std       0.500028     2.858878      3.465806   80715.248604     6.318153   \n",
            "min       0.000000     1.000000      0.001263   20062.000000    18.002337   \n",
            "25%       0.000000     3.000000      2.978895   87835.000000    23.420212   \n",
            "50%       0.000000     5.000000      5.904138  157830.000000    28.779074   \n",
            "75%       1.000000     8.000000      8.995663  228486.500000    34.320578   \n",
            "max       1.000000    10.000000     11.999313  299954.000000    39.997211   \n",
            "\n",
            "       triglycerides  phys_act_days     sleep_hr  heart_attack_risk  \n",
            "count    7963.000000    7963.000000  7963.000000        7963.000000  \n",
            "mean      418.370715       3.486877     7.022353           0.343966  \n",
            "std       223.794036       2.278560     1.987275           0.475060  \n",
            "min        30.000000       0.000000     4.000000           0.000000  \n",
            "25%       227.500000       2.000000     5.000000           0.000000  \n",
            "50%       419.000000       3.000000     7.000000           0.000000  \n",
            "75%       614.000000       5.000000     9.000000           1.000000  \n",
            "max       800.000000       7.000000    10.000000           1.000000  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Split blood pressure into systolic and diastolic\n",
        "print(\"Original BP column sample:\")\n",
        "print(train_data['bp'].head())\n",
        "\n",
        "# Split for training data\n",
        "train_data[['bp_systolic', 'bp_diastolic']] = train_data['bp'].str.split('/', expand=True)\n",
        "train_data['bp_systolic'] = pd.to_numeric(train_data['bp_systolic'])\n",
        "train_data['bp_diastolic'] = pd.to_numeric(train_data['bp_diastolic'])\n",
        "train_data = train_data.drop('bp', axis=1)\n",
        "\n",
        "# Split for test data\n",
        "test_data[['bp_systolic', 'bp_diastolic']] = test_data['bp'].str.split('/', expand=True)\n",
        "test_data['bp_systolic'] = pd.to_numeric(test_data['bp_systolic'])\n",
        "test_data['bp_diastolic'] = pd.to_numeric(test_data['bp_diastolic'])\n",
        "test_data = test_data.drop('bp', axis=1)\n",
        "\n",
        "print(\"\\n✅ Blood pressure split into systolic and diastolic!\")\n",
        "print(\"New columns created:\")\n",
        "print(train_data[['bp_systolic', 'bp_diastolic']].head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gTw0feI9maAN",
        "outputId": "89b6d676-705f-428b-def1-10f0dd713b9d"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original BP column sample:\n",
            "0     158/88\n",
            "1     165/93\n",
            "2     174/99\n",
            "3    163/100\n",
            "4      91/88\n",
            "Name: bp, dtype: object\n",
            "\n",
            "✅ Blood pressure split into systolic and diastolic!\n",
            "New columns created:\n",
            "   bp_systolic  bp_diastolic\n",
            "0          158            88\n",
            "1          165            93\n",
            "2          174            99\n",
            "3          163           100\n",
            "4           91            88\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert categorical (text) columns to numbers\n",
        "categorical_cols = ['sex', 'diet', 'country', 'continent', 'hemisphere']\n",
        "\n",
        "print(\"Converting text columns to numbers...\")\n",
        "for col in categorical_cols:\n",
        "    le = LabelEncoder()\n",
        "    # Fit on training data\n",
        "    train_data[col] = le.fit_transform(train_data[col].astype(str))\n",
        "    # Transform test data with same encoding\n",
        "    test_data[col] = le.transform(test_data[col].astype(str))\n",
        "    print(f\"✅ {col} converted\")\n",
        "\n",
        "print(\"\\n✅ All categorical variables converted to numbers!\")\n",
        "print(\"\\nSample of converted data:\")\n",
        "print(train_data[['sex', 'diet', 'country']].head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rjF_msgzmjbq",
        "outputId": "0d13e3cd-380f-47fb-ed95-0950f2c417a9"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Converting text columns to numbers...\n",
            "✅ sex converted\n",
            "✅ diet converted\n",
            "✅ country converted\n",
            "✅ continent converted\n",
            "✅ hemisphere converted\n",
            "\n",
            "✅ All categorical variables converted to numbers!\n",
            "\n",
            "Sample of converted data:\n",
            "   sex  diet  country\n",
            "0    1     0        0\n",
            "1    1     2        3\n",
            "2    0     1        6\n",
            "3    1     0        3\n",
            "4    1     2       16\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Separate features (X) and target (y)\n",
        "X = train_data.drop(['patient_id', 'heart_attack_risk'], axis=1)\n",
        "y = train_data['heart_attack_risk']\n",
        "\n",
        "print(f\"✅ Features prepared!\")\n",
        "print(f\"Number of features: {X.shape[1]}\")\n",
        "print(f\"Number of patients: {X.shape[0]}\")\n",
        "print(f\"\\nTarget distribution:\")\n",
        "print(y.value_counts())\n",
        "\n",
        "# Split into training and validation sets\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "print(f\"\\n✅ Data split complete!\")\n",
        "print(f\"Training set: {len(X_train)} patients\")\n",
        "print(f\"Validation set: {len(X_val)} patients\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SrDAwl_FmoA_",
        "outputId": "c94df5f7-e3bd-4b5e-d484-4538cfcc8aa2"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Features prepared!\n",
            "Number of features: 25\n",
            "Number of patients: 7963\n",
            "\n",
            "Target distribution:\n",
            "heart_attack_risk\n",
            "0    5224\n",
            "1    2739\n",
            "Name: count, dtype: int64\n",
            "\n",
            "✅ Data split complete!\n",
            "Training set: 6370 patients\n",
            "Validation set: 1593 patients\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Scale features to similar ranges\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_val_scaled = scaler.transform(X_val)\n",
        "\n",
        "print(\"✅ Features scaled successfully!\")\n",
        "print(f\"Shape of training data: {X_train_scaled.shape}\")\n",
        "print(f\"Shape of validation data: {X_val_scaled.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SRGcvvTQmqmn",
        "outputId": "874bc4ab-004e-410b-90e6-b51ddbe06bf3"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Features scaled successfully!\n",
            "Shape of training data: (6370, 25)\n",
            "Shape of validation data: (1593, 25)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create and train the model\n",
        "print(\"🚀 Training the model... (this may take 30-60 seconds)\")\n",
        "\n",
        "model = RandomForestClassifier(\n",
        "    n_estimators=200,           # Number of trees\n",
        "    max_depth=15,               # How deep each tree goes\n",
        "    min_samples_split=10,       # Minimum samples to split\n",
        "    min_samples_leaf=4,         # Minimum samples in leaf\n",
        "    class_weight='balanced',    # Handle imbalanced data\n",
        "    random_state=42,\n",
        "    n_jobs=-1                   # Use all CPU cores\n",
        ")\n",
        "\n",
        "model.fit(X_train_scaled, y_train)\n",
        "\n",
        "print(\"✅ Model training complete!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sb-8AQFwmsi0",
        "outputId": "4b446516-e942-45ea-86d7-5991dd1de311"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🚀 Training the model... (this may take 30-60 seconds)\n",
            "✅ Model training complete!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions on validation set\n",
        "y_pred = model.predict(X_val_scaled)\n",
        "y_pred_proba = model.predict_proba(X_val_scaled)[:, 1]\n",
        "\n",
        "# Calculate all metrics\n",
        "accuracy = accuracy_score(y_val, y_pred)\n",
        "precision = precision_score(y_val, y_pred)\n",
        "recall = recall_score(y_val, y_pred)\n",
        "f1 = f1_score(y_val, y_pred)\n",
        "roc_auc = roc_auc_score(y_val, y_pred_proba)\n",
        "\n",
        "# Display results (THIS IS IMPORTANT - YOU NEED SCREENSHOT OF THIS!)\n",
        "print(\"=\"*50)\n",
        "print(\"📊 MODEL PERFORMANCE METRICS\")\n",
        "print(\"=\"*50)\n",
        "print(f\"Accuracy:  {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall:    {recall:.4f}  ⭐ MOST IMPORTANT!\")\n",
        "print(f\"F1-Score:  {f1:.4f}\")\n",
        "print(f\"ROC-AUC:   {roc_auc:.4f}\")\n",
        "print(\"=\"*50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WbHtD5q6muu8",
        "outputId": "44a0d70b-aabb-4592-97e9-00efc818edc4"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==================================================\n",
            "📊 MODEL PERFORMANCE METRICS\n",
            "==================================================\n",
            "Accuracy:  0.6309\n",
            "Precision: 0.3413\n",
            "Recall:    0.0785  ⭐ MOST IMPORTANT!\n",
            "F1-Score:  0.1276\n",
            "ROC-AUC:   0.4997\n",
            "==================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# IMPROVED MODEL with focus on RECALL\n",
        "print(\"🚀 Training IMPROVED model focused on HIGH RECALL...\")\n",
        "\n",
        "# Use different approach - focus on catching positive cases\n",
        "model_improved = RandomForestClassifier(\n",
        "    n_estimators=300,\n",
        "    max_depth=None,              # No limit on depth\n",
        "    min_samples_split=2,         # More aggressive splitting\n",
        "    min_samples_leaf=1,\n",
        "    class_weight={0: 1, 1: 10},  # 10x weight on positive class!\n",
        "    random_state=42,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "model_improved.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Make predictions with lower threshold (catches more positives)\n",
        "y_pred_proba_improved = model_improved.predict_proba(X_val_scaled)[:, 1]\n",
        "\n",
        "# Use 0.3 threshold instead of 0.5 to catch more positive cases\n",
        "y_pred_improved = (y_pred_proba_improved >= 0.3).astype(int)\n",
        "\n",
        "# Calculate metrics\n",
        "accuracy_imp = accuracy_score(y_val, y_pred_improved)\n",
        "precision_imp = precision_score(y_val, y_pred_improved)\n",
        "recall_imp = recall_score(y_val, y_pred_improved)\n",
        "f1_imp = f1_score(y_val, y_pred_improved)\n",
        "roc_auc_imp = roc_auc_score(y_val, y_pred_proba_improved)\n",
        "\n",
        "print(\"=\"*50)\n",
        "print(\"📊 IMPROVED MODEL PERFORMANCE\")\n",
        "print(\"=\"*50)\n",
        "print(f\"Accuracy:  {accuracy_imp:.4f}\")\n",
        "print(f\"Precision: {precision_imp:.4f}\")\n",
        "print(f\"Recall:    {recall_imp:.4f}  ⭐ MOST IMPORTANT!\")\n",
        "print(f\"F1-Score:  {f1_imp:.4f}\")\n",
        "print(f\"ROC-AUC:   {roc_auc_imp:.4f}\")\n",
        "print(\"=\"*50)\n",
        "print(f\"\\n🎯 Recall improved from 0.0785 to {recall_imp:.4f}!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BfKbBK7wmyvs",
        "outputId": "cd7414c2-3f61-461b-9e95-4b354aaca6c0"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🚀 Training IMPROVED model focused on HIGH RECALL...\n",
            "==================================================\n",
            "📊 IMPROVED MODEL PERFORMANCE\n",
            "==================================================\n",
            "Accuracy:  0.4846\n",
            "Precision: 0.3436\n",
            "Recall:    0.5474  ⭐ MOST IMPORTANT!\n",
            "F1-Score:  0.4222\n",
            "ROC-AUC:   0.5061\n",
            "==================================================\n",
            "\n",
            "🎯 Recall improved from 0.0785 to 0.5474!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# FINAL MODEL - Maximum Recall Strategy\n",
        "print(\"🚀 Training FINAL model with MAXIMUM RECALL focus...\")\n",
        "\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "\n",
        "# Try Gradient Boosting - often better for imbalanced data\n",
        "model_final = GradientBoostingClassifier(\n",
        "    n_estimators=200,\n",
        "    learning_rate=0.1,\n",
        "    max_depth=5,\n",
        "    min_samples_split=2,\n",
        "    min_samples_leaf=1,\n",
        "    subsample=0.8,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "model_final.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Get probabilities\n",
        "y_pred_proba_final = model_final.predict_proba(X_val_scaled)[:, 1]\n",
        "\n",
        "# Try even LOWER threshold - 0.25 (very aggressive)\n",
        "y_pred_final = (y_pred_proba_final >= 0.25).astype(int)\n",
        "\n",
        "# Calculate metrics\n",
        "accuracy_final = accuracy_score(y_val, y_pred_final)\n",
        "precision_final = precision_score(y_val, y_pred_final)\n",
        "recall_final = recall_score(y_val, y_pred_final)\n",
        "f1_final = f1_score(y_val, y_pred_final)\n",
        "roc_auc_final = roc_auc_score(y_val, y_pred_proba_final)\n",
        "\n",
        "print(\"=\"*50)\n",
        "print(\"📊 FINAL MODEL PERFORMANCE\")\n",
        "print(\"=\"*50)\n",
        "print(f\"Accuracy:  {accuracy_final:.4f}\")\n",
        "print(f\"Precision: {precision_final:.4f}\")\n",
        "print(f\"Recall:    {recall_final:.4f}  ⭐ MOST IMPORTANT!\")\n",
        "print(f\"F1-Score:  {f1_final:.4f}\")\n",
        "print(f\"ROC-AUC:   {roc_auc_final:.4f}\")\n",
        "print(\"=\"*50)\n",
        "print(f\"\\n🎯 Recall improved to {recall_final:.4f}!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mePSZDyinA50",
        "outputId": "6ada6e0a-3ef9-43f7-ca05-bafbced94554"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🚀 Training FINAL model with MAXIMUM RECALL focus...\n",
            "==================================================\n",
            "📊 FINAL MODEL PERFORMANCE\n",
            "==================================================\n",
            "Accuracy:  0.4175\n",
            "Precision: 0.3356\n",
            "Recall:    0.7080  ⭐ MOST IMPORTANT!\n",
            "F1-Score:  0.4554\n",
            "ROC-AUC:   0.5045\n",
            "==================================================\n",
            "\n",
            "🎯 Recall improved to 0.7080!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ULTRA-AGGRESSIVE MODEL - Maximum Recall Push\n",
        "print(\"🚀 Training ULTRA-AGGRESSIVE model for MAXIMUM RECALL...\")\n",
        "\n",
        "# Retrain with even more extreme settings\n",
        "model_ultra = GradientBoostingClassifier(\n",
        "    n_estimators=300,\n",
        "    learning_rate=0.05,\n",
        "    max_depth=7,\n",
        "    min_samples_split=2,\n",
        "    min_samples_leaf=1,\n",
        "    subsample=1.0,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "model_ultra.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Try multiple thresholds to find the best\n",
        "thresholds = [0.15, 0.20, 0.25, 0.30]\n",
        "best_recall = 0\n",
        "best_threshold = 0\n",
        "best_metrics = {}\n",
        "\n",
        "y_pred_proba_ultra = model_ultra.predict_proba(X_val_scaled)[:, 1]\n",
        "\n",
        "print(\"\\nTesting different thresholds:\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "for threshold in thresholds:\n",
        "    y_pred_test = (y_pred_proba_ultra >= threshold).astype(int)\n",
        "\n",
        "    recall_test = recall_score(y_val, y_pred_test)\n",
        "    precision_test = precision_score(y_val, y_pred_test)\n",
        "    f1_test = f1_score(y_val, y_pred_test)\n",
        "\n",
        "    print(f\"Threshold {threshold}: Recall={recall_test:.4f}, Precision={precision_test:.4f}, F1={f1_test:.4f}\")\n",
        "\n",
        "    if recall_test > best_recall:\n",
        "        best_recall = recall_test\n",
        "        best_threshold = threshold\n",
        "        best_metrics = {\n",
        "            'recall': recall_test,\n",
        "            'precision': precision_test,\n",
        "            'f1': f1_test,\n",
        "            'accuracy': accuracy_score(y_val, y_pred_test)\n",
        "        }\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(f\"\\n🏆 BEST THRESHOLD: {best_threshold}\")\n",
        "print(f\"🎯 BEST RECALL: {best_recall:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uCg8h0rrnOxR",
        "outputId": "830915ad-b803-40ba-b16f-d46114f4da8c"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🚀 Training ULTRA-AGGRESSIVE model for MAXIMUM RECALL...\n",
            "\n",
            "Testing different thresholds:\n",
            "============================================================\n",
            "Threshold 0.15: Recall=0.9325, Precision=0.3436, F1=0.5022\n",
            "Threshold 0.2: Recall=0.8339, Precision=0.3457, F1=0.4888\n",
            "Threshold 0.25: Recall=0.6880, Precision=0.3520, F1=0.4657\n",
            "Threshold 0.3: Recall=0.5511, Precision=0.3540, F1=0.4311\n",
            "============================================================\n",
            "\n",
            "🏆 BEST THRESHOLD: 0.15\n",
            "🎯 BEST RECALL: 0.9325\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install imbalanced-learn library\n",
        "!pip install imbalanced-learn\n",
        "\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "print(\"🚀 Using SMOTE to balance the dataset...\")\n",
        "\n",
        "# Apply SMOTE to create synthetic samples\n",
        "smote = SMOTE(random_state=42, k_neighbors=3)\n",
        "X_train_smote, y_train_smote = smote.fit_resample(X_train_scaled, y_train)\n",
        "\n",
        "print(f\"\\nOriginal training set:\")\n",
        "print(f\"  Class 0 (No risk): {sum(y_train == 0)}\")\n",
        "print(f\"  Class 1 (At risk): {sum(y_train == 1)}\")\n",
        "\n",
        "print(f\"\\nAfter SMOTE:\")\n",
        "print(f\"  Class 0 (No risk): {sum(y_train_smote == 0)}\")\n",
        "print(f\"  Class 1 (At risk): {sum(y_train_smote == 1)}\")\n",
        "\n",
        "# Train model on balanced data\n",
        "model_smote = GradientBoostingClassifier(\n",
        "    n_estimators=300,\n",
        "    learning_rate=0.1,\n",
        "    max_depth=6,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "model_smote.fit(X_train_smote, y_train_smote)\n",
        "\n",
        "# Test with multiple thresholds\n",
        "y_pred_proba_smote = model_smote.predict_proba(X_val_scaled)[:, 1]\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"SMOTE MODEL - Testing thresholds:\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "best_recall_smote = 0\n",
        "best_threshold_smote = 0\n",
        "\n",
        "for threshold in [0.2, 0.25, 0.3, 0.35, 0.4]:\n",
        "    y_pred_test = (y_pred_proba_smote >= threshold).astype(int)\n",
        "\n",
        "    recall_test = recall_score(y_val, y_pred_test)\n",
        "    precision_test = precision_score(y_val, y_pred_test)\n",
        "    f1_test = f1_score(y_val, y_pred_test)\n",
        "\n",
        "    print(f\"Threshold {threshold}: Recall={recall_test:.4f}, Precision={precision_test:.4f}, F1={f1_test:.4f}\")\n",
        "\n",
        "    if recall_test > best_recall_smote:\n",
        "        best_recall_smote = recall_test\n",
        "        best_threshold_smote = threshold\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(f\"\\n🏆 BEST SMOTE RECALL: {best_recall_smote:.4f} at threshold {best_threshold_smote}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ibIA0mAAnnZn",
        "outputId": "cb02ec66-b4a2-4cda-e9fe-6e8bf8d37e6c"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: imbalanced-learn in /usr/local/lib/python3.12/dist-packages (0.14.0)\n",
            "Requirement already satisfied: numpy<3,>=1.25.2 in /usr/local/lib/python3.12/dist-packages (from imbalanced-learn) (2.0.2)\n",
            "Requirement already satisfied: scipy<2,>=1.11.4 in /usr/local/lib/python3.12/dist-packages (from imbalanced-learn) (1.16.2)\n",
            "Requirement already satisfied: scikit-learn<2,>=1.4.2 in /usr/local/lib/python3.12/dist-packages (from imbalanced-learn) (1.6.1)\n",
            "Requirement already satisfied: joblib<2,>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from imbalanced-learn) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl<4,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from imbalanced-learn) (3.6.0)\n",
            "🚀 Using SMOTE to balance the dataset...\n",
            "\n",
            "Original training set:\n",
            "  Class 0 (No risk): 4179\n",
            "  Class 1 (At risk): 2191\n",
            "\n",
            "After SMOTE:\n",
            "  Class 0 (No risk): 4179\n",
            "  Class 1 (At risk): 4179\n",
            "\n",
            "============================================================\n",
            "SMOTE MODEL - Testing thresholds:\n",
            "============================================================\n",
            "Threshold 0.2: Recall=0.7847, Precision=0.3437, F1=0.4780\n",
            "Threshold 0.25: Recall=0.6734, Precision=0.3455, F1=0.4567\n",
            "Threshold 0.3: Recall=0.5511, Precision=0.3444, F1=0.4239\n",
            "Threshold 0.35: Recall=0.4325, Precision=0.3440, F1=0.3832\n",
            "Threshold 0.4: Recall=0.3266, Precision=0.3358, F1=0.3312\n",
            "============================================================\n",
            "\n",
            "🏆 BEST SMOTE RECALL: 0.7847 at threshold 0.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Final predictions with SMOTE model\n",
        "best_model = model_smote\n",
        "best_thresh = best_threshold_smote\n",
        "\n",
        "test_pred_proba_best = best_model.predict_proba(X_test_scaled)[:, 1]\n",
        "test_predictions_best = (test_pred_proba_best >= best_thresh).astype(int)\n",
        "\n",
        "# Show final metrics on validation set\n",
        "y_pred_final = (model_smote.predict_proba(X_val_scaled)[:, 1] >= best_thresh).astype(int)\n",
        "\n",
        "print(\"=\"*50)\n",
        "print(\"📊 FINAL MODEL METRICS (SMOTE)\")\n",
        "print(\"=\"*50)\n",
        "print(f\"Accuracy:  {accuracy_score(y_val, y_pred_final):.4f}\")\n",
        "print(f\"Precision: {precision_score(y_val, y_pred_final):.4f}\")\n",
        "print(f\"Recall:    {recall_score(y_val, y_pred_final):.4f}  ⭐\")\n",
        "print(f\"F1-Score:  {f1_score(y_val, y_pred_final):.4f}\")\n",
        "print(f\"ROC-AUC:   {roc_auc_score(y_val, model_smote.predict_proba(X_val_scaled)[:, 1]):.4f}\")\n",
        "print(\"=\"*50)\n",
        "print(f\"Threshold used: {best_thresh}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        },
        "id": "D-_KxEYun6IX",
        "outputId": "8d876a5f-aa3e-489d-9593-474cb3024dbf"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'X_test_scaled' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-111932459.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mbest_thresh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbest_threshold_smote\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mtest_pred_proba_best\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbest_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_scaled\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mtest_predictions_best\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtest_pred_proba_best\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mbest_thresh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'X_test_scaled' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "031d6c4d",
        "outputId": "4c3c1381-813c-4f64-ec56-b5e9615c7666"
      },
      "source": [
        "# Scale the test data using the same scaler fitted on the training data\n",
        "X_test = test_data.drop('patient_id', axis=1) # Drop 'patient_id' from test data\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "print(\"✅ Test data scaled successfully!\")\n",
        "print(f\"Shape of test data: {X_test_scaled.shape}\")"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Test data scaled successfully!\n",
            "Shape of test data: (800, 25)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Final predictions with SMOTE model\n",
        "best_model = model_smote\n",
        "best_thresh = best_threshold_smote\n",
        "\n",
        "test_pred_proba_best = best_model.predict_proba(X_test_scaled)[:, 1]\n",
        "test_predictions_best = (test_pred_proba_best >= best_thresh).astype(int)\n",
        "\n",
        "# Show final metrics on validation set\n",
        "y_pred_final = (model_smote.predict_proba(X_val_scaled)[:, 1] >= best_thresh).astype(int)\n",
        "\n",
        "print(\"=\"*50)\n",
        "print(\"📊 FINAL MODEL METRICS (SMOTE)\")\n",
        "print(\"=\"*50)\n",
        "print(f\"Accuracy:  {accuracy_score(y_val, y_pred_final):.4f}\")\n",
        "print(f\"Precision: {precision_score(y_val, y_pred_final):.4f}\")\n",
        "print(f\"Recall:    {recall_score(y_val, y_pred_final):.4f}  ⭐\")\n",
        "print(f\"F1-Score:  {f1_score(y_val, y_pred_final):.4f}\")\n",
        "print(f\"ROC-AUC:   {roc_auc_score(y_val, model_smote.predict_proba(X_val_scaled)[:, 1]):.4f}\")\n",
        "print(\"=\"*50)\n",
        "print(f\"Threshold used: {best_thresh}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sQY_QOm3oPFm",
        "outputId": "01b5080f-dee0-432e-eeea-ef7ef59c90fd"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==================================================\n",
            "📊 FINAL MODEL METRICS (SMOTE)\n",
            "==================================================\n",
            "Accuracy:  0.4105\n",
            "Precision: 0.3437\n",
            "Recall:    0.7847  ⭐\n",
            "F1-Score:  0.4780\n",
            "ROC-AUC:   0.5087\n",
            "==================================================\n",
            "Threshold used: 0.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Make FINAL predictions on test data using the best model\n",
        "test_pred_proba_final = model_final.predict_proba(X_test_scaled)[:, 1]\n",
        "test_predictions_final = (test_pred_proba_final >= 0.25).astype(int)\n",
        "\n",
        "print(f\"✅ FINAL predictions complete!\")\n",
        "print(f\"\\nPrediction distribution:\")\n",
        "print(f\"No risk (0): {sum(test_predictions_final == 0)}\")\n",
        "print(f\"At risk (1): {sum(test_predictions_final == 1)}\")\n",
        "print(f\"Total: {len(test_predictions_final)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "55Sk8HGuomNa",
        "outputId": "cf0b2866-8ed9-4542-cd7a-66ade48081fa"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ FINAL predictions complete!\n",
            "\n",
            "Prediction distribution:\n",
            "No risk (0): 207\n",
            "At risk (1): 593\n",
            "Total: 800\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create FINAL submission file\n",
        "submission_final = pd.DataFrame({\n",
        "    'patient_id': test_data['patient_id'],\n",
        "    'heart_attack_risk': test_predictions_final\n",
        "})\n",
        "\n",
        "print(\"FINAL Submission preview:\")\n",
        "print(submission_final.head(15))\n",
        "print(\"\\nChecking format...\")\n",
        "print(f\"Columns: {list(submission_final.columns)}\")\n",
        "print(f\"Total rows: {len(submission_final)}\")\n",
        "\n",
        "# IMPORTANT: Replace TeamCode and TeamName with YOUR actual team info!\n",
        "submission_final.to_csv('EN17_TeamMatrix_Task1_Predictions.csv', index=False)\n",
        "\n",
        "print(\"\\n✅ FINAL CSV file created successfully!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R9ZPJoIAo8cn",
        "outputId": "1a439d3f-1d48-4b60-aaa2-fba47ea00d99"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FINAL Submission preview:\n",
            "   patient_id  heart_attack_risk\n",
            "0     VRK5064                  1\n",
            "1     NEN2365                  1\n",
            "2     KXT2493                  1\n",
            "3     TKO0406                  1\n",
            "4     GDP2405                  0\n",
            "5     GRQ8132                  1\n",
            "6     KUL5067                  1\n",
            "7     OTZ1268                  0\n",
            "8     EZN4283                  0\n",
            "9     HVE8034                  1\n",
            "10    GIN1693                  1\n",
            "11    LEG9626                  0\n",
            "12    DWZ6826                  1\n",
            "13    PHK4364                  1\n",
            "14    VAZ4776                  1\n",
            "\n",
            "Checking format...\n",
            "Columns: ['patient_id', 'heart_attack_risk']\n",
            "Total rows: 800\n",
            "\n",
            "✅ FINAL CSV file created successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BwNZJ-WRpk2u"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}